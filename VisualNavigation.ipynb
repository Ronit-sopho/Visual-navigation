{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from IPython.display import HTML, clear_output\n",
    "\n",
    "import cv2\n",
    "import multiprocessing as mp\n",
    "import sys, os, threading\n",
    "\n",
    "from segment import road_segmentation\n",
    "from ipmdistance import getDistance\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 12)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU found\n"
     ]
    }
   ],
   "source": [
    "# Turn on the detection pipeline\n",
    "from detect import *\n",
    "from utils import convert_to_original_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_model/model.ckpt\n",
      "Model restored in 0.626s\n"
     ]
    }
   ],
   "source": [
    "# Reset previous initiation\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Instantiate Detection Object\n",
    "detection_object = Detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to load images into memory\n",
    "def load_images(path):\n",
    "\n",
    "    getFrames = []\n",
    "    for imgs in sorted(os.listdir(path)):\n",
    "        getFrames.append(Image.open(os.path.join(path, imgs)))\n",
    "    return getFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the bounding boxes for detected objects and initiate trackers for them\n",
    "\n",
    "def runDetection(frame):\n",
    "    \n",
    "    pilImage = Image.fromarray(frame)\n",
    "    outputImage, bounding_boxes = detection_object.infer(pilImage)\n",
    "    outputFrame = np.asarray(outputImage)\n",
    "    \n",
    "    # Initiate trackers for the bounding boxes\n",
    "    detectedObjects = []\n",
    "    results = []\n",
    "    trackers = []\n",
    "    \n",
    "    for cls, bboxes in bounding_boxes.items():\n",
    "        for box, score in bboxes:\n",
    "            if(np.all(box>0)):\n",
    "                detectedObjects.append(box)\n",
    "    \n",
    "    ntrackers = len(detectedObjects)\n",
    "    for r in range(ntrackers):\n",
    "        trck = cv2.TrackerMIL_create()\n",
    "        x0,y0,x1,y1 = tuple(detectedObjects[r].astype(int))\n",
    "        if x1-x0<=500 and y1-y0<=500:\n",
    "            try:\n",
    "                trck.init(frame, (x0,y0,x1-x0, y1-y0))\n",
    "                trackers.append(trck)\n",
    "                results.append((x0,y0,x1-x0,y1-y0))\n",
    "            except:\n",
    "                print('Error Encountered')\n",
    "                continue\n",
    "    \n",
    "    return outputFrame, trackers, results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to track an object in consecutive frames\n",
    "def SingleTracker(trackerObject, vid_frame, output):\n",
    "\n",
    "    try:\n",
    "        ret, bbox = trackerObject.update(vid_frame)\n",
    "    except:\n",
    "        pass\n",
    "    if(ret):\n",
    "        output.put(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Multiple Instance Tracking with threading in python\n",
    "def parallelTracking(frame, trackers, output):\n",
    "    \n",
    "    threads = [threading.Thread(target=SingleTracker, args=(trck, frame, output,)) for trck in trackers]\n",
    "    for t in threads: t.start()\n",
    "    for t in threads: t.join()\n",
    "    \n",
    "    results = [output.get() for t in threads]\n",
    "    for t in trackers: del t\n",
    "    \n",
    "    for box in results:\n",
    "        p1 = (int(box[0]), int(box[1]))\n",
    "        p2 = (int(box[0]+box[2]), int(box[1]+box[3]))\n",
    "        cv2.rectangle(frame, p1, p2, (0,0,200), 2, 1)\n",
    "    \n",
    "    return frame, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Predictions found in 5.441s\n",
      "detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronit/Documents/BTP/Final_navigation/segment.py:13: RuntimeWarning: divide by zero encountered in log\n",
      "  ii_image = 0.5 + np.log(inp_img[:,:,1]) - alpha*np.log(inp_img[:,:,2]) - (1-alpha)*np.log(inp_img[:,:,0])\n",
      "/home/ronit/Documents/BTP/Final_navigation/segment.py:13: RuntimeWarning: invalid value encountered in subtract\n",
      "  ii_image = 0.5 + np.log(inp_img[:,:,1]) - alpha*np.log(inp_img[:,:,2]) - (1-alpha)*np.log(inp_img[:,:,0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Tracked\n",
      "2\n",
      "Tracked\n",
      "3\n",
      "Tracked\n",
      "4\n",
      "Tracked\n",
      "5\n",
      "Tracked\n",
      "6\n",
      "Tracked\n",
      "7\n",
      "Tracked\n",
      "8\n",
      "Tracked\n",
      "9\n",
      "Tracked\n",
      "10\n",
      "Predictions found in 0.601s\n",
      "detected\n",
      "11\n",
      "Tracked\n",
      "12\n",
      "Tracked\n",
      "13\n",
      "Tracked\n",
      "14\n",
      "Tracked\n",
      "15\n",
      "Tracked\n",
      "16\n",
      "Tracked\n",
      "17\n",
      "Tracked\n",
      "18\n",
      "Tracked\n",
      "19\n",
      "Tracked\n",
      "20\n",
      "Predictions found in 0.606s\n",
      "detected\n",
      "21\n",
      "Tracked\n",
      "22\n",
      "Tracked\n"
     ]
    }
   ],
   "source": [
    "# Define video handle\n",
    "cap = cv2.VideoCapture(\"input_video.mp4\")\n",
    "\n",
    "# Counter for frames\n",
    "count = 0\n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            cap.release()\n",
    "            print(\"Released Video Resource\")\n",
    "            break\n",
    "        \n",
    "        H,W,_ = frame.shape\n",
    "        print(count)\n",
    "        \n",
    "        # Run YOLO detection for every 10th frame\n",
    "        if count%10==0:\n",
    "            frame, trackers, results = runDetection(frame)\n",
    "#             print('detected')\n",
    "            output = mp.Queue()\n",
    "        else:\n",
    "            frame, results = parallelTracking(frame, trackers, output)\n",
    "#             print('Tracked')\n",
    "        \n",
    "        output = mp.Queue()\n",
    "        thread_distance = threading.Thread(target = getDistance, args=(frame, results, output,))\n",
    "        thread_segment = threading.Thread(target = road_segmentation, args = (frame, output,))\n",
    "        threads = [thread_distance, thread_segment]\n",
    "        for t in threads: t.start()\n",
    "        for t in threads: t.join()\n",
    "        res = [output.get() for t in threads]\n",
    "        for r in res:\n",
    "            if type(r)==type({}):\n",
    "                distance_to_objects = r\n",
    "            else:\n",
    "                frame = r\n",
    "        \n",
    "        for k in distance_to_objects.keys():\n",
    "            mid_x = int(distance_to_objects[k][0]+distance_to_objects[k][2]/2)\n",
    "            mid_y = int(distance_to_objects[k][1]+distance_to_objects[k][3])\n",
    "            cv2.putText(frame, str(k)[:4]+' meters',(mid_x,mid_y+3), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 7, cv2.LINE_AA)\n",
    "\n",
    "        frame = cv2.resize(frame, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "        count+=1\n",
    "        cv2.imshow(\"OUTPUT\", frame)\n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "        if(k==27):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        cv2.imwrite(\"output/frames/frame_{}.png\".format(count), frame)\n",
    "except KeyboardInterrupt:\n",
    "    cap.release()\n",
    "    clear_output()\n",
    "    print(\"Released Video Resource due to interrupt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
